<!DOCTYPE html>
<html lang="en">
<head>
<title>Synthetic Dataset generation for machine learning</title>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="description" content="vCard template project">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" type="text/css" href="styles/bootstrap-4.1.2/bootstrap.min.css">
<link href="plugins/font-awesome-4.7.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
<link rel="stylesheet" type="text/css" href="plugins/mCustomScrollbar/jquery.mCustomScrollbar.css">
<link rel="stylesheet" type="text/css" href="styles/education.css">
<link rel="stylesheet" type="text/css" href="styles/education_responsive.css">
</head>
<body>

<div class="super_container">

	<!-- Header -->

	<header class="header">
		<div class="header_content d-flex flex-row align-items-center justify-content-start">
			<div class="logo">Suhail<span>.</span>CV</div>
			<div class="main_nav d-flex flex-row align-items-end justify-content-start">
				<ul class="d-flex flex-row align-items-center justify-content-start">
					<li><a href="index.html">About</a></li>
					<li><a href="skills.html">Skills</a></li>
					<!-- <li><a href="services.html">Services</a></li> -->
					<li><a href="experience.html">Experience</a></li>
					<li ><a href="education.html">Education</a></li>
					<li class="active"><a href="portfolio.html">Portfolio</a></li>
					<!-- <li><a href="testimonials.html">Testimonials</a></li> -->
					<!-- <li><a href="contact.html">Contact</a></li> -->
				</ul>
				<div class="header_button ml-auto">
					<a href="https://suhailpallathsulaiman.github.io/Suhail_Pallath_Sulaiman_Resume.pdf">Resume</a>
					<div class="d-flex flex-column align-items-center justify-content-center"><img src="images/download.png" alt=""></div>
				</div>
			</div>
			<!-- Menu -->
	<div class="menu">
		<div class="menu_content d-flex flex-row align-items-start justify-content-end">
			<div class="hamburger ml-auto">menu</div>
			<div class="menu_nav text-right">
				<ul>
					<li><a href="index.html">About</a></li>
					<li><a href="skills.html">Skills</a></li>
					<li><a href="experience.html">Experience</a></li>
					<li><a href="education.html">Education</a></li>
					<li><a href="portfolio.html">Portfolio</a></li>
					<!-- <li><a href="contact.html">Contact</a></li> -->
				</ul>
			</div>
		</div>
	</div>
		</div>
	</header>

	<div class="content_container">
		<div class="main_content_outer d-flex flex-xl-row flex-column align-items-start justify-content-start">

			<!-- General Information -->
			<div class="general_info d-flex flex-xl-column flex-md-row flex-column">
				<div>
					<div class="general_info_image">
						<div class="background_image" style="background-image:url(images/suhail.jpg)"></div>
						<div class="header_button_2">
							<a href="https://suhailpallathsulaiman.github.io/Suhail_Pallath_Sulaiman_Resume.pdf">Resume</a>
							<div class="d-flex flex-column align-items-center justify-content-center"><img src="images/download.png" alt=""></div>
						</div>
					</div>
				</div>
				<div class="general_info_content">
					<div class="general_info_content_inner mCustomScrollbar" data-mcs-theme="minimal-dark">
									<div class="social_container">
							<ul class="d-flex flex-row align-items-start justify-content-start">
								<li><a href="https://www.linkedin.com/in/suhailpallathsulaiman/"><i class="fa fa-linkedin" aria-hidden="true"></i></a></li>
								<li><a href="https://github.com/suhailpallathsulaiman"><i class="fa fa-github" aria-hidden="true"></i></a></li>
								<li><a href="https://www.youtube.com/user/zulusvideo"><i class="fa fa-youtube" aria-hidden="true"></i></a></li>
								<li><a href="https://www.instagram.com/suhail_bin_sulaiman/"><i class="fa fa-instagram" aria-hidden="true"></i></a></li>
								<li><a href="https://www.facebook.com/suhail.p.sulaiman"><i class="fa fa-facebook" aria-hidden="true"></i></a></li>

							</ul>
						</div>
						<ul class="general_info_list">
							<li class="d-flex flex-row align-items-center justify-content-start">
								<div class="general_info_icon d-flex flex-column align-items-start justify-content-center"><img src="images/icon_1.png" alt=""></div>
								<div class="general_info_text">Name: <span>Suhail Pallath Sulaiman</span></div>
							</li>
							<li class="d-flex flex-row align-items-center justify-content-start">
								<div class="general_info_icon d-flex flex-column align-items-start justify-content-center"></div>
								<div class="general_info_text">Location: <span>Evanston IL USA</span></div>
							</li>
							<li class="d-flex flex-row align-items-center justify-content-start">
								<div class="general_info_icon d-flex flex-column align-items-start justify-content-center"><img src="images/icon_2.png" alt=""></div>
								<div class="general_info_text">Date of Birth: <span>March 5, 1993</span></div>
							</li>
							<li class="d-flex flex-row align-items-center justify-content-start">
								<div class="general_info_icon d-flex flex-column align-items-start justify-content-center"><img src="images/icon_3.png" alt=""></div>
								<div class="general_info_text"><a href="mailto:contact@linque.com?subject=Job_Inquiry">suhailsulaiman2018@u.northwestern.edu</a></div>
							</li>
							<li class="d-flex flex-row align-items-center justify-content-start">
								<div class="general_info_icon d-flex flex-column align-items-start justify-content-center"><img src="images/icon_4.png" alt=""></div>
								<div class="general_info_text">+1 224 716 7143</div>
							</li>


						</ul>


					</div>
				</div>
			</div>

			<!-- Main Content -->

<div class="main_content">
<div class="main_content_scroll mCustomScrollbar" data-mcs-theme="minimal-dark">
<div class="proj_title_container d-flex flex-column align-items-start justify-content-end">

<!-- <div class="proj_title">Synthetic dataset generation for machine learning</div> -->
<h1 class="proj_title">Synthetic dataset generation for machine learning</h1>
</div>
<!-- 				<div class="main_content_scroll mCustomScrollbar" data-mcs-theme="minimal-dark"> -->
<!-- <div class="video-responsive">
    <iframe width="420" height="315" src="https://www.youtube.com/embed/wTG6hmNOVkA" frameborder="0" allowfullscreen></iframe>
</div> -->

<div class="video-holder">
  <div id="video-container">
      <iframe width="1000" height="563" src="https://www.youtube.com/embed/wTG6hmNOVkA" frameborder="0" allowfullscreen>        </iframe> 
  </div>

</div>
<br><br>

<!-- Skills Content -->
<div class="edu_title">Summary</div>
<div class="edu_text">
<p>One of the most important problems that are faced by a machine learning, is the time and effort required for collection and preparation of training data. This package generates synthetic datasets for training object recognition models. A huge dataset of fake simulated images of any object scanned by a depth camera is generated, so that machine learning models could be trained on a variety of data to make them more robust. The project package performs following tasks
</p><p>● Scan the object to collect point clouds of the object using RGBD camera from different angles.
</p><p>● Stitch the point clouds together to create a 3D point cloud of the object scanned.
</p><p>● Create a 3d model from the 3d point cloud using surface reconstruction
</p><p>● Generate fake images of the object by simulating different lighting conditions, pose, scale etc of the object using Gazebo.
</p><p>● Add random backgrouds to the collected images.
</p><p>● Prepare the data as a compatible input to a machine learning model.
</p><p>● Train a Tensorflow object detection model on the images generated.
</p><p>● Detect the object and its location in a camera feed after training.</p>
</div>
<br><br>

<div class="edu_title">Step 1: Scan the object</div>
<div class="edu_text">
<p>ASUS Xtion Pro Live RGBD sensor is used to scan the object. For demontration purposes the object was placed on top of a turntable that is rotated with hand to make sure all parts of the object is being scanned. The scanner.cpp program helps in scanning. Once the code is run, a pointcloud visualiser will pop up showing the output of the depth camera. The program provides three option
</p><p>● Crop the output :- The user will have the option to crop the output by inputting X, Y, Z limits, so that only the object of interest is scanned.
</p><p>● Start Saving:- Once user is happy with adjusting the cropbox, he can start saving the poinclouds and rotate the object in front of the sensor so that all sides of the object is scanned. The user can pause the saving anytime and resume after that.
</p><p>● Pause Saving:- This option can be used to pause saving the pointclouds.
</p><p>The output from the scan program will be a bunch of pointclouds as shown below.
</div>

<div class="video-holder">
  <div id="video-container">
      <img class="resimg" width="1000" height="563" src="https://suhailpallathsulaiman.github.io/images/scan_output.gif"   allowfullscreen> 
  </div>
</div>

<br><br>
<div class="edu_title">Step 2: Stitch the pointclouds</div>
<div class="edu_text">
<p>The code reads these pointclouds as input and gives out a merged 3D pointcloud of the object scanned as shown below.


</p><p>The user have optional control overfollowing things while stiching
</p><p>● Choose between RANSAC and coarse ICP algorithm for global registration.
</p><p>● Choose between fine ICP and color ICP algorithm for local registration.
</p><p>● Choose how individual pointclouds are merged ie., Pairwise or merging to a base pointcloud
</p><p>● Input the fitness value below which the merge should be rejected
</p><p>The final output will be saved in both .pcd and .ply file formats.
</div>

<div class="video-holder">
  <div id="video-container">
      <img class="resimg" width="1000" height="563" src="https://suhailpallathsulaiman.github.io/images/merge_output.gif"  allowfullscreen> 
  </div>
</div>

<div class="edu_text">
<p>The animation below shows the pointcloud stitching process on a human scan.</p>
</div>


<div class="video-holder">
  <div id="video-container">
      <img class="resimg" width="1000" height="563" src="https://suhailpallathsulaiman.github.io/images/human_stiching.gif"  allowfullscreen> 
  </div>
</div>

<br><br>
<div class="edu_title">Step 3: Surface reconstruction</div>
<div class="edu_text">
<p>The code for performing surface reconstruction is not yet implemented. For time being Meshlab is used. The .ply file is imported in to meshlab and ball pivoting surface reconstruction algorithm is used to reconstruct the surface. A texture map is also generated in the form of a .png file so that the mesh will have color when opened in simulation software like Gazebo. The reconstructed mesh is then exported as a COLLADA file. An example is shown below.

</div>

<div class="video-holder">
  <div id="video-container">
      <img class="resimg" width="1000" height="563" src="https://suhailpallathsulaiman.github.io/images/surface_reconstruction_output.gif"  allowfullscreen> 
  </div>
</div>

<br><br>
<div class="edu_title">Step 4: Generate Simulated Images.</div>
<div class="edu_text">
<p>A Gazebo model is created using the COLLADA file. The model can be created for any .dae file by just changing a path in a skeleton model. Automation of generating Gazebo model from .dae file is in progress.
</p><p>The image_grabber ROS package helps in generating the fake simulated images from the model. The image_grabber.launch file performs the following tasks.
</p><p>● Opens a empty world
</p><p>● Spawn the object model of which the fake images have to be generated.
</p><p>● Spawn a camera model. Once the camera model is spawned it starts saving the images in its vision.
</p><p>● Starts the set_model_state.py node which changes the pose of both the camera and the object in such a way that the camera covers all the angles of the object. The gazebo world in action is shown below.</p>
	
	<div class="video-holder">
  <div id="video-container">
      <img class="resimg" width="1000" height="563" src="https://suhailpallathsulaiman.github.io/images/gazebo_simulation.gif"  allowfullscreen> 
  </div>
</div>
</p><p>Example output images fromthe Gazebo simulationis shown below.</p>

	<div class="video-holder">
  <div id="video-container">
      <img class="resimg" width="1000" height="563" src="https://suhailpallathsulaiman.github.io/images/gazebo_output.png"  allowfullscreen> 
  </div>
</div>
	
</div>

<br><br>
<div class="edu_title">Step 5: Add random backgrounds to Images and prepare the dataset.</div>
<div class="edu_text">
<p>Gazebo give images with empty backgrounds, which is not a good dataset for training object recognition models. The bounding_n_background.py program performs the following tasks.
</p><p>● Reads the output images from gazebo, crops out only the object of interest from the images using OpenCV, and paste the cropped objects to random images provided as input, so that the machine learning model will be more robust in recognising the object within a lot of other objects.Some example images are shown below
</p>

	<div class="video-holder">
  <div id="video-container">
      <img class="resimg" width="1000" height="563" src="https://suhailpallathsulaiman.github.io/images/bg_output.png"  allowfullscreen> 
  </div>
</div>
	<p>● This program also generate a .csv file which have all the data required for training the machine learning model like the bounding box of the object in the image (which is found using OpenCV), dimensions of the image and the label for the object (The name with which the trained model should identify the object)
</p><p>Now the generate_tfrecord.py program reads the .csv files and generates this data in tfrecord file format, which is the input type that is used for training tensorflow object recognition API.
</p>
	
</div>

<br><br>
<div class="edu_title">Step 6: Training a machine learning model.</div>
<div class="edu_text">
<p>Tensorflow object detection API was used for demonstration purpose. The train.py program starts the training process.
</p><p>The graph showing the total loss with number of steps during the training process is shown below.
</div>

	<div class="video-holder">
  <div id="video-container">
      <img class="resimg" width="1000" height="563" src="https://suhailpallathsulaiman.github.io/images/tensorflow_total_loss.png"  allowfullscreen> 
  </div>
</div>
<br><br>
<div class="edu_title">Step 7: Live detection</div>
<div class="edu_text">
<p>The object_detection .py file opens a video recording for testing the Machine learning model after training. The training is not yet perfect, but still the model is detecting the object most of the time. This can be made more robust by training on a huge dataset generated using the package with more simulated conditions incorporated
</p>
</div>

<div class="video-holder">
  <div id="video-container">
      <iframe width="1000" height="563" src="https://www.youtube.com/embed/w1X17ET0MNY" frameborder="0" allowfullscreen>        </iframe> 
  </div>

</div>


					</div>

				</div>
			</div>
		</div>
<div align='center'>
	<!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
Copyright &copy;<script>document.write(new Date().getFullYear());</script> All rights reserved | This template is made with <i class="fa fa-heart-o" aria-hidden="true"></i> by <a href="https://colorlib.com" target="_blank">Colorlib</a>
<!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. --></div>

	</div>
</div>

<script src="js/jquery-3.2.1.min.js"></script>
<script src="styles/bootstrap-4.1.2/popper.js"></script>
<script src="styles/bootstrap-4.1.2/bootstrap.min.js"></script>
<script src="plugins/mCustomScrollbar/jquery.mCustomScrollbar.js"></script>
<script src="plugins/easing/easing.js"></script>
<script src="plugins/parallax-js-master/parallax.min.js"></script>
<script src="js/education.js"></script>
</body>
</html>
